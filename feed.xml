<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Bai_Mingze</title>
  <id>http://www.baimingze.com/</id>
  <link href="http://www.baimingze.com/"/>
  <link href="http://www.baimingze.com/feed.xml" rel="self"/>
  <updated>2015-06-28T20:34:00+01:00</updated>
  <author>
    <name>Bai_Mingze</name>
  </author>
  <entry>
    <title>Is Apache Spark going to replace Hadoop (Translated Version in Chinese)</title>
    <link rel="alternate" href="http://www.baimingze.com/blog/2015/06/is-apache-spark-going-to-replace-hadoop-translated-version-in-chinese.html"/>
    <id>http://www.baimingze.com/blog/2015/06/is-apache-spark-going-to-replace-hadoop-translated-version-in-chinese.html</id>
    <published>2015-06-28T20:34:00+01:00</published>
    <updated>2015-06-30T21:42:39+01:00</updated>
    <author>
      <name>Bai_Mingze</name>
    </author>
    <content type="html">&lt;p&gt;[版权所有，转载请注明出处：baimingze.github.io]&lt;/p&gt;

&lt;p&gt;在言必称大数据的时代，Hadoop风起云涌，早已成为大数据在技术领域的代名词。然后长江后浪推前浪，Hadoop才进化到2.0版不久，一个号称能够把Hadoop计算速度提高100倍的Spark又横空出世。Spark真的能把Hadoop计算速度提高100倍么？答案是肯定的，在某些迭代次数很多的计算中，采用内存存储中间数据的Spark相比采用硬盘存储中间数据的Hadoop在I/O性能上优势不言而喻。但Spark同时声称，即使对于很多超过内存资源承载能力，需采用硬盘存储的数据处理用例，Spark依然可以凭借其数据结构设计上的优势将速度提高10倍以上。&lt;/p&gt;

&lt;p&gt;业界人士都很关注，Spark会替代Hadoop么？我找到一篇写的很好的博文《&lt;a href="http://aptuz.com/blog/is-apache-spark-going-to-replace-hadoop/"&gt;Is Apache Spark going to replace Hadoop?&lt;/a&gt;》，特将其翻译过来练练手。以下为翻译内容，原作者为Jameel Mohammed。&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;什么是Apache Spark？
为什么它在大数据领域如此火爆？
Apache Spark会替代Hadoop么？
如果你计划进入大数据分析业务领域，是不是真的需要关注Spark？
希望本博文能为你解答一些可能近期萦绕在你脑中的问题。&lt;/p&gt;

&lt;h2&gt;Apache Spark简介&lt;/h2&gt;

&lt;p&gt;和Hadoop一样，Spark也是一种在分布式计算集群上执行常见数据分析任务的框架系统。 它的特点之一是计算过程中的数据可以全部存储在内存中而不需要写入硬盘，从而提供了相比mapreduce更快的计算速度。此外，它还可以：
 - 运行在已搭建好的Hadoop 集群上
 - 访问Hadoop 的数据存储系统（HDFS）
 - 处理Hive存储的结构化数据
 - 处理来自HDFS,Flume,Kafka,Twitter等平台的流数据&lt;/p&gt;

&lt;p&gt;&lt;img alt="Spark结构图" src="http://aptuz.com/static/media/uploads/blog/spark_arc.png" /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;译者注：该图清晰地表明了Spark向开发真和用户提供的语言支持，以及向下提供的数据输入接口支持。图中最上方的蓝色方块里包含了三种语言：Java、Scala、Python，它们是目前Spark支持的3种语言，采用这3种语言可以较轻松地建立Spark数据分析任务。中间灰色方框代表Spark，它包含了3个数据访问子系统：Spark核心系统，Spark SQL和Spark Stream。Spark核心系统处理HDFS和HBase里存储的NoSQL数据;Spark SQL负责处理Hive里存储的结构化（也可以理解成SQL存储的）数据; Spark Stream则可以处理Flume等等所存储的流数据。注意，HDFS、Hbase和Hive被包含在图底部的一个叫做Hadoop的蓝色椭圆形里，因为它们三者都是Hadoop生态系统中的一员。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2&gt;Apache Spark会替代Hadoop么？&lt;/h2&gt;

&lt;p&gt;Hadoop也是”在分布式计算集群上执行常见数据分析任务的框架系统“。不过它所运行的任务是”map/reduce“类型，这些任务通常需要很长的时间才能完成，几分钟甚至几个小时。而Spark的设计理念是：运行于Hadoop集群之上，替代传统批处理式的map/reduce模型，从而能实时完成流数据处理任务以及能在几秒内完成的交互式查询任务。所以，其实Hadoop既支持传统的map/reduce模型，又支持Spark的。为什么这么说呢？因为Hadoop并不单纯是执行MapReduce的一个计算引擎或者编程模型，而代表了一个生态系统，如下图所示。&lt;/p&gt;

&lt;p&gt;&lt;img alt="Hadoop生态系统图" src="http://aptuz.com/static/media/uploads/blog/hadoop_echosystem.png" /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;译者注：Hadoop”生态系统“，”物种“很丰富，层次也很分明。可是，图中各个软件/技术（线形方框）之间的连线，以及它们与小圆点之间连线的具体含义没想明白，望指教。
一时兴起，打个比方：有一个名叫Hadoop鱼缸里养了一条名叫MapReduce的鱼，以及其它一些水草、小虾米（HDFS、YARN）什么的，构成了一个完整的生态系统。但是由于很久一段时间以来，鱼缸里就一条鱼，大家也称这条鱼为Hadoop。现在鱼缸里又放进来一条名叫Spark的鱼，大家都很关心Spark这条游的更快的鱼会取代Hadoop鱼缸里那条名叫MapReduce的鱼么？&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2&gt;Hadoop MapReduce vs. Spark, 该选谁？&lt;/h2&gt;

&lt;p&gt;Spark尽量把数据存储在RAM里，从而减少网络和硬盘I/O，当然会比Hadoop MapReduce更快一些。但是它对计算机硬件的配置要求也更高，毕竟大内存也不是说上就能上的，成本可不低。所以答案是：具体问题具体分析，而且随着计算机硬件参数和价格的变化而变化。&lt;/p&gt;

&lt;h2&gt;Hadoop Mapreduce 和Apache Spark的区别&lt;/h2&gt;

&lt;p&gt;简单一句话：Spark将数据存在内存中而Hadoop则把数据存在硬盘里。Hadoop采用”多份拷贝“（replication）来实现容错机制，而Spark采用另外一种数据存储模型：弹性分布式数据集（Resilient Distributed Datasets，RDD）。RDD采用一种更聪明的方法来实现容错，可以最小化网络I/O。详见UC Berkeley的链接”&lt;a href="http://www.eecs.berkeley.edu/Pubs/TechRpts/2011/EECS-2011-82.html"&gt;Resilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing.&lt;/a&gt;“。&lt;/p&gt;

&lt;p&gt;Spark的学术论文的描述为：”RDDs通过一种概念沿袭（notion lineage）的方法来实现容错机制：如果一个RDD的某一部分丢失了，该RDD应该拥有足够的信息来重建所丢失的部分“。因此系统不再需要放置多份拷贝来实现容错了。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;仅从博文中的字句描述，我还以为RDD拥有磁盘阵列RAID一样的纠错机制，直到阅读了论文后才发现不是这么回事。在Spark的计算过程中有一系列的RDD转换过程：RDD1-&amp;gt;RDD2-&amp;gt;RDD3-&amp;gt;&amp;hellip;，如果中间的RDD3的某一部分丢失，那么根据RDD2和基于RDD2的转换，可以重新记算出RDD3的丢失部分。但是这个记算过程和完全重新执行基于RDD2的转换有何区别？是部分与整体的关系么？计算量有多大？我暂未在论文中找到答案。论文原文如下：”RDDs reconstruct lost partitions through lineage : an RDD has enough information about how it was derived from other RDDs to rebuild just the missing partition, without having to checkpoint any data.“&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2&gt;学Apache Spark之前需要先学Hadoop么？&lt;/h2&gt;

&lt;p&gt;不需要。
Spark是一个独立的项目，只不过在Hadoop2.0版和YARN之后，Spark凭借它能运行在HDFS之上和计算速度快的优势，积极融入Hadoop生态系统而异军突起。Spark也借此成为Hadoop 生态系统中另一个重要的数据处理引擎，极大增加了Hadoop栈的能力范围，创利于商业界和业界。&lt;/p&gt;

&lt;p&gt;对开发者来说，在这二者之间毫无重叠。在Hadoop框架中你需要继承Java类，编写MapReduce任务。而Spark只是一个可以通过函数调用来进行并行计算的库。
对计算机集群的操作员来说，在一些通用技能上还是有一部分重叠的，如监控配置（monitoring configuration）、代码部署（code deployment）等。&lt;/p&gt;

&lt;h2&gt;Apache Spark 的特性&lt;/h2&gt;

&lt;p&gt;此处概述一些Spark在大数据领域凸现的一些重要特性，内容来自&lt;a href="http://spark.apache.org/"&gt;http://spark.apache.org/&lt;/a&gt;。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;速度
Spark基于内存进行计算，将Hadoop上的一些基于硬盘的计算任务加快了100倍； 而一些同样基于硬盘的Spark计算，相对Hadoop仍能提高10倍。Spark成功的诀窍在于——减少硬盘读写次数，因为它能将计算过程中间的数据存储在内存中。 这里面的核心技术名叫弹性分布式数据集（Resilient Distributed Datasets，RDD），它允许Spark透明地（transparently）将数据存储在内存中，并且只在必需的时候才持久化写入到硬盘中。数据处理中的性能瓶颈主要在于硬盘的读写，相比Hadoop，Spark能将读写次数减少一大半，岂能不快？
&lt;img alt="计算时间比较图" src="http://aptuz.com/static/media/uploads/blog/.thumbnails/logistic-regression.png/logistic-regression-250x129.png" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;易用性
Spark支持Java, Scala或Python三种语言，函数库调用简单快捷。它允许开发人员使用自己熟悉的语言快速地创建和运行并行程序。Spark集成内置了超过80个高级“运算子”（operator），有了它们，用户甚至可以用交互命令行的方式来查询数据，不需编写大段大段的代码。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;采用Spark Python API编写字数统计的例子：&lt;/p&gt;
&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1
2
3
4&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;datafile = spark.textFile("hdfs://...")
datafile.flatMap(lambda line: line.split())
        .map(lambda word: (word, 1))
        .reduceByKey(lambda x, y: x+y)
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;联合使用SQL, 流处理和复杂分析
除了简单的“map”和“reduce”之外，Spark还支持SQL查询、流数据以及复杂分析任务（如机器学习、图算法等）。更牛的是，Spark还支持在单个工作流中无缝联合使用它们。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;多种平台上运行
Spark可以运行在Hadoop，Mesos上，也可以运行在单机或者云平台上。它能访问的数据源包括HDFS、Cassandra、HBase S3等。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Spark明显超越Hadoop的用例&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;迭代计算步骤很多的机器学习算法&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;可交互的数据挖掘和数据处理&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;完全兼容Apache Hive数据仓库系统，并比Hive快100倍以上&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;流处理：在实时流数据中进行日志处理、欺诈检测（报警、集成、分析）&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;传感器数据处理：将多点检测、终点汇集的数据放置在内存中进行处理，简单快速&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Spark虽然很强，但是仍旧还在成长中。直白点说，Bug还不少。&lt;/p&gt;

&lt;h2&gt;到你了，开始学吧&lt;/h2&gt;

&lt;p&gt;你很容易就能用Spark写出强大的大数据应用，相信我。
你已有的Hadoop 和/或编程技能可以让你在短短几分钟内就能富有成效地与你的数据交互。
你可以这样开始学：
下载： http://spark.incubator.apache.org/downloads.html
快速开始: http://spark.incubator.apache.org/docs/latest/quick-start.html
Spark 峰会 2013 (Dec. 2, 2013): http://spark-summit.org
Amazon Web Services 文档: https://aws.amazon.com/articles/4926593393724923&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>A visiting to the Sanger Institute</title>
    <link rel="alternate" href="http://www.baimingze.com/blog/2015/06/a-visiting-to-the-sanger-institute.html"/>
    <id>http://www.baimingze.com/blog/2015/06/a-visiting-to-the-sanger-institute.html</id>
    <published>2015-06-21T10:30:00+01:00</published>
    <updated>2015-06-21T19:31:42+01:00</updated>
    <author>
      <name>Bai_Mingze</name>
    </author>
    <content type="html">&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;参观Sanger中心
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Welcome Trust Genome Campus, 坐落在剑桥以南一个名叫Hinxton的村庄。这里风景秀丽，物产丰饶，旁有康河潺潺而过。&lt;/p&gt;

&lt;p&gt;20世纪90年代初始，这片广袤的麦田里成长起两座世界闻名的生物学研究机构，那便是Welcome Trust Sanger Institue和European Bioinformatics Institute。这俩机构虽分属不同政府管辖，但相生相伴，共同成长，不觉已匆匆走过23年的时光。
图片&lt;/p&gt;

&lt;p&gt;我来到EBI访学已4个多月，几乎每天中午都在Sanger中心Sulston大楼的咖啡厅吃午饭，却从没进入Sanger中心去一探究竟，心中难免向往，想看看生物信息的数据都是在什么样的环境下在什么样的科学家手中产生的。&lt;/p&gt;

&lt;p&gt;机会终于来了，有次在QQ群里看到剑桥学联旅游部在发布Sanger中心参观广告（由旅游部副部长、在Sanger工作的丁丁女士组织），便赶紧报名参加。终在6月16日进入神秘的Sanger中心，得偿所愿。&lt;/p&gt;

&lt;p&gt;一行20多人在Genome Campus大门集和签到之后，由Sanger中心的Steve带领前往Sulston大楼的小会议室集中“授课”。Steve给大家作了基因组学/生物信息学基础知识的普及，这是因为Sanger也经常接待中小学生来参观的原因，因此都是从最基础的讲起。于是，我又上了一次生动的生物基础课，重温了DNA双螺旋结构、基因、染色体等知识。&lt;/p&gt;

&lt;p&gt;当然，首先要介绍的就是Sanger他老人家到底是谁？
图片
墙上幻灯显示的是Sanger他老人家以及他所发明的DNA测序方法，也是他获得第二个诺贝尔奖的成果——DNA测序方法，该方法目前都还在继续使用。这就是给我们“上课”的小教室，双螺旋结构的教具相当齐全，且可拆卸成一个一个的碱基，也很生动。多边形桌方便大家分组讨论，可惜今天时间有限，只是分组研究各种模型，没有讨论。&lt;/p&gt;

&lt;p&gt;提及DNA的双螺旋结构，大家都知道Francis Crick and James D. Watson 最先提出DNA的双螺旋，但是他们得出最终结论的关键数据却是来自这位美女科学家（Rosalind Elsie Franklin）做出的完美X射线图。也是她的同事不小心把未发表成果给竞争对手看，导致别人抢了先，但她本人并不在乎。只可惜她英年早逝，没有活到DNA双螺旋结构获诺贝尔奖的时刻，不然她也很可能获奖的。
图片&lt;/p&gt;

&lt;p&gt;Steve给我们演示了第一代测序仪核心部件：跑电泳的凝胶被做成了一根根的细线并通上电，让DNA序列从样品盒开始往终端跑，在终端扫描读取萤光信号，测出DNA序列。
图片&lt;/p&gt;

&lt;p&gt;之后便是下一代测序（Next Generation Sequencing），也算是第二代测序技术了，核心就是这小小的玻片。个人感觉这发展思路有点像集成电路，设备越来越小，最终做成芯片。
图片&lt;/p&gt;

&lt;p&gt;接下来介绍人类基因组计划，英国占了30%多的比例，全部在Sanger中心完成,领衔的是John Sulston，也是我们上课和参观的测序实验室所在这栋楼名字的来源。
图片&lt;/p&gt;

&lt;p&gt;HGP计划完成后，他们还真把第一个人类基因组打印成书，收藏在博物馆里了。Sanger中心所展示的几本书是他们自己所测出来的部分，可以看到，这套全是由agtc组成的“天书”是多么厚实，又是多么的难解读。书的封面专门强调：这是面向全世界免费共享，自由使用的。&lt;/p&gt;

&lt;p&gt;图片&lt;/p&gt;

&lt;p&gt;图片&lt;/p&gt;

&lt;p&gt;课讲完后，接着是咖啡休息时间。我开始还以为要自己到旁边的咖啡厅去买，出门惊讶地发现Sanger中心在课堂外免费提供咖啡、茶、饼干，待遇实在太好了。可惜光聊天去了，没有照相，不过场景跟EBI每天都有的免费下午茶差不多。&lt;/p&gt;

&lt;p&gt;大家自由交流了一段时间之后，终于要去参观数据中心和实验室了。&lt;/p&gt;

&lt;p&gt;数据中心建在另外一栋楼的地下一层，中心外面一条走廊供参观，走廊里还陈设了当年HGP计划时的测序仪。&lt;/p&gt;

&lt;p&gt;图片&lt;/p&gt;

&lt;p&gt;图片&lt;/p&gt;

&lt;p&gt;出了数据中心，回到Sulston楼，进军最核心的测序实验室。在迷宫之中穿梭了好几分钟之后才来到测序实验室。&lt;/p&gt;

&lt;p&gt;实验室一角
图片&lt;/p&gt;

&lt;p&gt;实验室另一角度
图片&lt;/p&gt;

&lt;p&gt;二代测序仪1
图片
二代测序仪2
图片&lt;/p&gt;

&lt;p&gt;三代测序仪
图片&lt;/p&gt;

&lt;p&gt;三代测序仪特写，花花绿绿的图案随时在变动，实时显示测出的序列。
图片&lt;/p&gt;

&lt;p&gt;这是我第一次近距离接触生物信息数据的来源——1-3代测序仪。听Steve说他们这里还有几台Oxford Nanopore Technologies的测序仪，这可是第四代的哟！等它们全面铺开占领市场时，每个人1000美元的价格就能拥有自己的基因组数据了。每人一本天书，这是多大的数据？想想都醉了。&lt;/p&gt;

&lt;p&gt;HGP计划早已落幕，未来就在精准医疗计划。英国也有类似的的大规模测序+医疗计划，那就是来自GenomicsEngland的100,000人基因组计划。未来的大规模测序中心就在这里，马上就快要落成。
图片&lt;/p&gt;

&lt;p&gt;（拍摄地点是我办公室所在的EBI South Building）&lt;/p&gt;

&lt;p&gt;实验室参观完毕之后，还留了点时间供大家一起继续讨论交流，我们又围到1代测序仪那里继续研究它的结构。&lt;/p&gt;

&lt;p&gt;Steve非常敬业，错过了午饭时间也坚持到最后，把每个参观者都送上车之后才离开。最后离开的是同样辛苦的组织者丁丁，不光坚持到最后，中间还跑前跑后准备零钱、联络汽车等。向他们表示诚挚的谢意。&lt;/p&gt;

&lt;p&gt;参观完之后大家都纷纷把自己的照片共享出来。本文中有三幅照片就是其他团员拍摄的，在此也向所有团员表示感谢。&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>One possible solution for getting black screen when logout/reboot on Linux</title>
    <link rel="alternate" href="http://www.baimingze.com/blog/2015/06/one-possible-solution-for-getting-black-screen-when-logout-reboot-on-linux.html"/>
    <id>http://www.baimingze.com/blog/2015/06/one-possible-solution-for-getting-black-screen-when-logout-reboot-on-linux.html</id>
    <published>2015-06-14T11:09:00+01:00</published>
    <updated>2015-06-14T11:39:02+01:00</updated>
    <author>
      <name>Bai_Mingze</name>
    </author>
    <content type="html">&lt;p&gt;I have recently installed Fedora 22(KDE spin) on my laptop(ThinkPad T440, with the Inetel HD graphic card).&lt;/p&gt;

&lt;p&gt;After I logged in the system, everything was fine with the plasma desktop.&lt;/p&gt;

&lt;p&gt;But when I try to logout/reboot(either from KDE or konsole),  I got a black screen, no text, no cursor, just the fan&amp;rsquo;s working noise, telling me that the computer was still working at some level. By the way, the Ctrl+Alt+F1/F2&amp;hellip;got no response neither.&lt;/p&gt;

&lt;p&gt;I have reset the runlevel to 3 and then try to use &amp;ldquo;startx&amp;rdquo;, then I got a black screen on start! Even through I can logged in to KDE at runlevel 5 before.&lt;/p&gt;

&lt;p&gt;After doing google, I got some ideas from the other&amp;rsquo;s posts. And I found a way can help me to get rid of the black screen. &lt;/p&gt;

&lt;p&gt;The main idea is remove the &amp;ldquo;nomodeset&amp;rdquo; from boot. Here is my way indetail:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;backup&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1
2&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;cp /boot/grub2/grub.cfg /boot/grub2/grub.cfg.bak
cp /etc/default/grub /etc/default/grub.bak
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;remove &amp;ldquo;nomodeset&amp;rdquo; from these files with your editor&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;enjoy yourself&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
</content>
  </entry>
  <entry>
    <title>Are you ready for the open science</title>
    <link rel="alternate" href="http://www.baimingze.com/blog/2015/06/are-you-ready-for-the-open-science.html"/>
    <id>http://www.baimingze.com/blog/2015/06/are-you-ready-for-the-open-science.html</id>
    <published>2015-06-07T08:44:00+01:00</published>
    <updated>2015-06-13T14:55:48+01:00</updated>
    <author>
      <name>Bai_Mingze</name>
    </author>
    <content type="html">&lt;p&gt;[版权所有，欢迎转载，转载请注明出处：baimingze.github.io]&lt;/p&gt;

&lt;p&gt;说open science，得先说开源。开源，也就是Open source，混迹于IT领域的人，应该都不会陌生。即使你只是普通的用户，你也肯定与开源软件亲密接触过，除非你告诉我你从没有摸过Android手机。&lt;/p&gt;

&lt;p&gt;Android可以说是Linux操作系统（影响力最大的开源软件）的儿子，它继承了Linux的核心。不过，它的外在却由Google 一手掌控，并不完全开放。就好比去天体海滩玩，大家都脱的光洁溜溜一览无余，~赤裸~坦诚相见，就Android把自己包裹的严严实实。直白的说，你这是居心不良，故意来占人便宜的，自然招来Linux开发者的强烈不满。他们纷纷指责Google只知道索取，不知道奉献,一双眼睛贼溜溜盯着别人的身体，自己的却不让人看到。再加上Google也算名门望族，Android也是身材婀娜，因此一帮“萎缩男”努力扯掉Android身上那套ASL衣服的心情也是很急迫的。当年一帮开源届大佬纷纷表态，想拉Android下水，但是Google也死拉着不放。Google这么做也是有原因的，他是为了保护硬件厂商开发Android硬件驱动的积极性，保证它们的驱动代码不会被强制开放给社区。是非过错暂不评论，无疑Google的政策在商业上是成功的。&lt;/p&gt;

&lt;p&gt;总而言之，开源软件的本质就是，我的软件代码是公开的，随便看，随便抄。但是这是有条件的，你用了我的代码之后，你的软件拿出来公开的时候，你的代码也必须遵守同样的开源协议，向所有人开放（GPL类）。Linux就是在这个环境下由开源精英们聚沙成塔，抚养成人，到如今能与Windows、Apple系列OS三分天下。之后为了鼓励一些公司也参与开源社区，又产生了Apache Software License所属的（BSD类协议），它规定你可以使用开源代码，而且发布软件的时候也可以不公开你自己的代码。这个条件很优厚了，相当于随便给人用，当然底线是不能剽窃别人的成果，把别人的代码说成是自己开发的。&lt;/p&gt;

&lt;p&gt;要说剽窃这个东西，还真的有，而且很多。前几天看到一个中国作者与BMC Systems Biology 期刊PK，原因是该刊某篇文章（也是中国团队）发布的软件的核心算法部分剽窃了他的代码，结果该刊编辑处理投诉时一拖再拖，拖了一年多，给了剽窃者重新发布新版软件并删除剽窃代码的机会，最终给了一个引用不当的判词，轻轻放过。原作者还在斗争中，详情看&lt;a href="http://ygc.name/2014/11/23/proper-use-of-gosemsim/"&gt;这里&lt;/a&gt;。这种证据确凿（两个软件代码都发布在共享平台CRAN上）的剽窃打击起来尚且如此困难，那些偷偷把别人代码拿来改改界面就说是自主知识产权来搞软件著作权登记骗点小钱就更不用说了。但是也有胆大的，骗国家核高基之类的大钱，甚至染指国家最高科技荣誉奖。&lt;/p&gt;

&lt;p&gt;言归正传，多点正能量，少点负能量。科技发展洪流滔滔，势不可当。随着社交媒体的发展，IT领域的开源精英们也迎来了自己的社交平台：GitHub。与我们的微薄一样，“粉丝”们可以近距离观察自己的“偶像”，与“偶像”直接互动。当然IT精英们可不比娱乐明星，他们的目标是推动科技进步，而不是满足粉丝的心理欲望。在GitHub上，如果你“崇拜”某个“英雄”，与他互动的方式不是给他发私信示爱，发微薄表支持，而是阅读他的代码，找bug，提feature，加issue，fork他的代码并加以修改，改完了如果你觉得还不错，还可以pull-request要求他把你改的代码合并到他的代码里，成为发布版的一部分！ 目前我还没听说哪个娱乐明星与粉丝一起互动完成某个作品，但是在GitHub，这样的事情每天都在发生。&lt;/p&gt;

&lt;p&gt;更牛b的是，互动多了，你的技术水平也上去了，只要你想到一两个好的创意并实现，你也可以成为“英雄”。想get IT技能？想追逐世界潮流？来GitHub吧。&lt;/p&gt;

&lt;p&gt;写到这个地方，回过头去瞄了一眼题目“Are you ready for the open science”，才发现我绕了半天还没到主题。不知道今天高考有没有考语文？如果这是高考作文，看来是拿不了高分了。之所以用英文标题，是因为我用的博客软件发布时都是按标题来作url，中文url支持不好而且看起来很怪，请原谅了。&lt;/p&gt;

&lt;p&gt;为什么前面要扯一堆开源和github？那是因为现在科学家也进驻GitHub了！昨天看到一个美女科学家Erin McKiernan的博客（看照片应该是美女，ps痕迹不重,想看美女科学家真容的请点&lt;a href="http://en.gravatar.com/emckiernan#photo-1"&gt;这里&lt;/a&gt;.看介绍，她是一名神经科学家，按我初浅的理解，可能是和《生活大爆炸》里面sheldon的女朋友的工作有些类似，但是Erin不光要做实验，还要用算法/软件分析她所获得的实验数据。写到这里我又不禁想到老话题：现在哪行哪业不需要编程？&lt;/p&gt;

&lt;p&gt;以下部分译自Erin McKiernan的博客&lt;a href="https://emckiernan.wordpress.com/2015/06/04/becoming-a-more-open-scientist/"&gt;Becoming a more open scientist&lt;/a&gt;，我翻译得可能会有一口大老爷们的腔调，想听美女口音的请原谅。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;过去几个月里我有一种感觉，就是我的研究工作还不够开放,我觉得我应该做的更好。其实我的所有科研文章都已经提供给大家自由下载，甚至是还没发表的预印本（preprint）都拿出来了。但我一直都有更近一步、把我的代码和数据全都共享出来的想法，只是至今还没有做到。今天我不想再拖下去了。&lt;/p&gt;

&lt;p&gt;想要我的数据？给你！想要我的代码？也给你！什么？你还想要知道我是怎么一步一步地分析数据的？你还想把我文章里的图表都照着画出来？也没问题，全都给你！&lt;/p&gt;

&lt;p&gt;因为今天我开设了我的github repository&lt;a href="https://github.com/emckiernan/eki-study"&gt;主页&lt;/a&gt;(真的是第一次哟！)。这里面包含了我最近一篇文章预印本的数据和代码，我也会马上再更新一下这篇文章的版本。现在，我会很乐意就我共享在github上的资料回答你的问题，特别是如何用ipython notebook（也是我的第一次哦）详细记录的电生理学数据的处理过程以及如何分析从电生理学数据里抽取出来的bursting数据。&lt;/p&gt;

&lt;p&gt;等我有时间的时候，我还会用博客记录如何获取到这些数据以及如何创建repository。因为这是我第一次这样做，在这过程中我也学会了很多方法使我的数据和代码变的更加有用，我甚至还学会了如何优化我的代码（译者注：分享的过程中也可以很大程度提高自己！）我要感谢 Ross Mounce ，他在如何共享我的数据上提供了很多很好的建议；我还要感谢 Marco Herrera Valdez 为我早期版本的notebook提供了很好的反馈。准备数据的过程不那么繁琐，但是如果要作的更好，我们还是需要关注一下需要投入多少时间和技能。&lt;/p&gt;

&lt;p&gt;现在请下载我的数据，玩的开心,然后我你的想法！我发现github和ipython notebooks确实非常强大，它们也是开创科学的重要力量。 我也很兴奋，能在我的工作开创中用到它们。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;翻译到此结束。我必须得承认，如果我是搞神经科学的，我必然要去她的repository，成为她的粉丝，分析她的数据，向她提问，跟她互动。
Erin还有很多博客讨论open science的，等有空了仔细阅读一下。&lt;/p&gt;

&lt;p&gt;现在该回答标题那个问题了。其实我是在向自己提问：你准备好了么？ 到EBI访问4个月期间，接触了他们的开发方式和阅读了许多博客之后，我从心底认可了开源软件/开放科学的理念。因此，我想我的答案是，追随美女科学家的脚步，努力开放。至少，已经发表/写成的成果是必须要开放的，这是与同行互动、增加自己影响力的有效手段。但是也不是彻底开放，对于还没有出成果的项目，得有些技巧，不能让竞争者、基金控制者轻易掌握你的开发进度，否则就被别人抢了先，或者说你工作都做的差不多了，还要我资助你干嘛？&lt;/p&gt;

&lt;p&gt;附1：今天又是决定一大批年轻人未来命运的时刻，在此祝我的外甥开心同学，以及全国的高考学子们考出自己满意的成绩。&lt;/p&gt;

&lt;p&gt;附2：我在EBI上的工作全在github上完成的，你可以在我的repository看到我都参与了哪些开发项目，每天怎么跟同事互动，也可以看到我每天都提交了什么代码。因为github最根本的服务不是社交，而是开发过程的版本控制，整个过程中的每一条代码的更改,每一条需求的提出和解决都是记录在github上的。我的repository地址是：https://github.com/baimingze， 请多指教！&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>attending the bible study</title>
    <link rel="alternate" href="http://www.baimingze.com/blog/2015/05/attending-the-bible-study.html"/>
    <id>http://www.baimingze.com/blog/2015/05/attending-the-bible-study.html</id>
    <published>2015-05-29T11:44:00+01:00</published>
    <updated>2015-06-13T14:55:48+01:00</updated>
    <author>
      <name>Bai_Mingze</name>
    </author>
    <content type="html">&lt;p&gt;前些天某晚去参加了一个中国人的团契活动，印象深刻。&lt;/p&gt;

&lt;p&gt;我决定去参加这次活动，主要有两个原因：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;邀请我的那个朋友人很好，我们经常在回去的大巴上聊天，大家也聊的很熟了。多次相邀，盛情难却，我就答应了。&lt;/li&gt;
&lt;li&gt;来了快四个月了，我基本适应了这边的生活和工作，那么其他中国人是什么样子的,尤其是那些住了很多年的中国人，他们在这里生活愉快么？平时都做些什么？我对他们的各种情况也有着强烈的兴趣。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;晚上7点朋友开车来接我，我们一起去了一个购物中心旁边的一个教堂里。据朋友说，10多年前他初到剑桥都是来的这个教堂。&lt;/p&gt;

&lt;p&gt;我们到的时候已经有几个中国人在那里了，大家看到我这个新朋友到来都热情地打招呼。晚饭前大家都三三两两地围在一起聊天。让我诧异的是有个活泼的外国姑娘，普通话说的比我还标准！还时常谈一点高铁价格贵之类的话题，看来是经常去中国的。&lt;/p&gt;

&lt;p&gt;晚饭后，开始说是有两个活动，一个是查经，一个是听一个刚从大陆巡游回来的牧师讲座。有个姓黄的“传导(？)”问我想参加哪个？我虽读过圣经，但是还是更喜欢听人讲自己的见闻，所以选择了听讲座。后来才发现，大家都选择了听讲座：）&lt;/p&gt;

&lt;p&gt;讲座开始了。&lt;/p&gt;

&lt;p&gt;主讲是一个来英国几十年的老牧师，香港人，以前似乎在考文垂那边传教。这次主要受到香港一个浸信会？的资助，到大陆各个城市访问。牧师每到一个城市，就召集以前从英国回国的弟兄姐妹（也就是传说中的海归）一起聚会，从照片来看，基本都是在聚餐，享受各地美食。 当然除了吃饭以外，牧师的工作职责还是要履行的。他跟这些弟兄姐妹聊生活聊工作，有时还给他们开讲座，题目叫‘拍拖的学问(？)’。这是因为海归的弟兄姐妹主要有两类，一类是大学生，一类是访问学者。而这些大学生海归后，普遍都面临着找到一份好工作以及找到人生伴侣的双重压力。牧师主要介绍他们的情况，每当聊到一个弟兄姐妹有困难时，便说，“让我们为他／她祈祷吧”。&lt;/p&gt;

&lt;p&gt;从这些话语，我感受到了宗教的魅力。在你孤独、彷徨、煎熬、痛苦的时候，有一个人，不为钱财也不为其它物质利益，关心你，爱护你;有一群人，不为钱财也不为其他物质利益，欢迎你，包容你。大家一起唱抚慰心灵的歌，一起分享心中的苦闷，你也成为这团体里重要的一员。有这么一个团体，你还愿意远离么？&lt;/p&gt;

&lt;p&gt;上面这段话，如果几年前的我看到，会很鄙视现在的我。那时，我以为人只需要有理性，或至少应该努力去追求理性；而不懂得，人首先是感性的动物，后来才发展出理性的思维方式。尊重、满足人的感性需求，才是真正的理性行为。&lt;/p&gt;

&lt;p&gt;牧师讲了快一个多钟头，之后就是祷告。出来时已经快9点半了。朋友送我到家后，我匆忙煎了两根香肠，夹在面包片里，再切一些黄瓜和番茄并撒上萨拉酱，就是第二天的午餐了。&lt;/p&gt;

&lt;p&gt;附记：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;吃饭的闲聊过程中，认识了一个在剑桥大学访学的兽医专业哥们，以及一个在剑桥制药公司工作的哥们。因为专业有相关性，我跟他们聊的比较热呼。我跟他们聊各种组学，药物靶点筛选，cas9基因敲除等话题，他们很惊异我这个计算机出生的人也懂这些。哈哈，殊不知我早已是生物信息的人了。当然，与这些生物医药领域的专家聊天时，我最关心的就是他们平时都处理些什么数据，用些什么生物信息工具，但是由于时间有限，没有就这个话题深入下去。写到这里突然想起某个同学的签名里说（好象是转述某大佬说的）：生物的范围有多广，生物信息的就有多广。可以想象，在全社会都信息化，大数据化的时代，大生物领域的数据整理和知识发现需要大量的人才来帮助他们开发工具以及分析数据。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;兽医专业那哥们来了大半年了，也还没伦敦逛过。当然我也一样，前两个月同事还老问我周末去伦敦了没，我每次都回答没去，后来也就不问了：）。那哥们不去的原因是，周六忙国内学生的事，周日要去教堂，实在没时间。我也差不多，周日要忙学生的事，以及准备下一周的晚饭。周六虽说有时间，但是也懒得跑伦敦那么远，只在近处走走逛逛以及看看书。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;回来的路上跟朋友聊信仰。我说生物领域的科学家相对其他领域的科学家信神的应该更少一些，因为搞生物的难免会触碰到进化论和神创论的分歧，但是咱生物信息领域有一个顶级科学家，他是人类基因组计划的领头人，同时却也是信上帝的。他听了很是诧异，想与我深入研究，可惜那时我已经到家了。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;这是我决定开始长期写博客的第一篇博客。坚持写博客的目的如下：&lt;/p&gt;
&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1
2
3&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;- 锻炼写作能力
- 整理思路
- 借博客平台与人交流
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;请多多指教！&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;文中(？)代表我是听来的不知道实际怎么写，或者虽然看到了，但是记不清楚.&lt;/p&gt;
</content>
  </entry>
</feed>
